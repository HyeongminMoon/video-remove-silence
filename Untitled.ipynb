{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05023f8-5a09-4d14-b9a0-ee840dd02be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import wave\n",
    "import webrtcvad\n",
    "import numpy as np\n",
    "import librosa\n",
    "import webrtcvad\n",
    "import IPython.display as ipd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0e9ff3-55e4-4cf5-9b27-6b7033e055f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_silences(filename):\n",
    "    global args\n",
    "    blend_duration = 0.005\n",
    "    with wave.open(filename) as wav:\n",
    "        size = wav.getnframes()\n",
    "        channels = wav.getnchannels()\n",
    "        sample_width = wav.getsampwidth()\n",
    "        frame_rate = wav.getframerate()\n",
    "        max_value = 1 << (8 * sample_width - 1)\n",
    "        half_blend_frames = int(blend_duration * frame_rate / 2)\n",
    "        blend_frames = half_blend_frames * 2\n",
    "        assert size > blend_frames > 0\n",
    "        square_threshold = max_value ** 2 * 10 ** (args.threshold_level / 10)\n",
    "        blend_squares = collections.deque()\n",
    "        blend = 0\n",
    "\n",
    "        def get_values():\n",
    "            frames_read = 0\n",
    "            while frames_read < size:\n",
    "                frames = wav.readframes(min(0x1000, size - frames_read))\n",
    "                frames_count = len(frames) // sample_width // channels\n",
    "                for frame_index in range(frames_count):\n",
    "                    yield frames[frame_index*channels*sample_width:(frame_index+1)*channels*sample_width]\n",
    "                frames_read += frames_count\n",
    "\n",
    "        def get_is_silence(blend):\n",
    "            results = 0\n",
    "            frames = get_values()\n",
    "            for index in range(half_blend_frames):\n",
    "                frame = next(frames)\n",
    "                square = 0\n",
    "                for channel in range(channels):\n",
    "                    value = int.from_bytes(frame[sample_width*channel:sample_width*channel+sample_width], 'little', signed=True)\n",
    "                    square += value*value\n",
    "                blend_squares.append(square)\n",
    "                blend += square\n",
    "            for index in range(size-half_blend_frames):\n",
    "                frame = next(frames)\n",
    "                square = 0\n",
    "                for channel in range(channels):\n",
    "                    value = int.from_bytes(frame[sample_width*channel:sample_width*channel+sample_width], 'little', signed=True)\n",
    "                    square += value*value\n",
    "                blend_squares.append(square)\n",
    "                blend += square\n",
    "                if index < half_blend_frames:\n",
    "                    yield blend < square_threshold * channels * (half_blend_frames + index + 1)\n",
    "                else:\n",
    "                    result = blend < square_threshold * channels * (blend_frames + 1)\n",
    "                    if result:\n",
    "                        results += 1\n",
    "                    yield result\n",
    "                    blend -= blend_squares.popleft()\n",
    "            for index in range(half_blend_frames):\n",
    "                blend -= blend_squares.popleft()\n",
    "                yield blend < square_threshold * channels * (blend_frames - index)\n",
    "\n",
    "        is_silence = get_is_silence(blend)\n",
    "\n",
    "        def to_regions(iterable):\n",
    "            iterator = enumerate(iterable)\n",
    "            while True:\n",
    "                try:\n",
    "                    index, value = next(iterator)\n",
    "                except StopIteration:\n",
    "                    return\n",
    "                if value:\n",
    "                    start = index\n",
    "                    while True:\n",
    "                        try:\n",
    "                            index, value = next(iterator)\n",
    "                            if not value:\n",
    "                                yield start, index\n",
    "                                break\n",
    "                        except StopIteration:\n",
    "                            yield start, index+1\n",
    "                            return\n",
    "\n",
    "        threshold_frames = int(args.threshold_duration * frame_rate)\n",
    "        silence_regions = ( (start, end) for start, end in to_regions(is_silence) if end-start >= blend_duration )\n",
    "        silence_regions = ( (start + (half_blend_frames if start > 0 else 0), end - (half_blend_frames if end < size else 0)) for start, end in silence_regions )\n",
    "        silence_regions = [ (start, end) for start, end in silence_regions if end-start >= threshold_frames ]\n",
    "        including_end = len(silence_regions) == 0 or silence_regions[-1][1] == size\n",
    "        silence_regions = [ (start/frame_rate, end/frame_rate) for start, end in silence_regions ]\n",
    "        # print(args.save_silence)\n",
    "        if args.save_silence:\n",
    "            with wave.open(args.save_silence, 'wb') as out_wav:\n",
    "                out_wav.setnchannels(channels)\n",
    "                out_wav.setsampwidth(sample_width)\n",
    "                out_wav.setframerate(frame_rate)\n",
    "                for start, end in silence_regions:\n",
    "                    wav.setpos(start)\n",
    "                    frames = wav.readframes(end-start)\n",
    "                    out_wav.writeframes(frames)\n",
    "\n",
    "    return silence_regions, including_end\n",
    "\n",
    "def transform_duration(duration):\n",
    "    global args\n",
    "    return args.constant + args.sublinear * math.log(duration + 1) + args.linear * duration\n",
    "\n",
    "def format_offset(offset):\n",
    "    return '{}:{}:{}'.format(int(offset) // 3600, int(offset) % 3600 // 60, offset % 60)\n",
    "\n",
    "def closest_frames(duration, frame_rate):\n",
    "    return int((duration + 1 / frame_rate / 2) // (1 / frame_rate))\n",
    "\n",
    "def compress_audio(wav, start_frame, end_frame, result_frames):\n",
    "    # print(start_frame, end_frame, result_frames)\n",
    "    if result_frames == 0:\n",
    "        return b''\n",
    "    elif result_frames == end_frame - start_frame:\n",
    "        # print(\"same\")\n",
    "        wav.setpos(start_frame)\n",
    "        return wav.readframes(result_frames)\n",
    "    else:\n",
    "        channels = wav.getnchannels()\n",
    "        sample_width = wav.getsampwidth()\n",
    "        frame_width = sample_width*channels\n",
    "        if result_frames*2 <= end_frame - start_frame:\n",
    "            left_length = result_frames\n",
    "            right_length = result_frames\n",
    "        else:\n",
    "            left_length = (end_frame - start_frame + 1) // 2\n",
    "            right_length = end_frame - start_frame - left_length\n",
    "        crossfade_length = right_length + left_length - result_frames\n",
    "        crossfade_start = (result_frames - crossfade_length) // 2\n",
    "        wav.setpos(start_frame)\n",
    "        left_frames = wav.readframes(left_length)\n",
    "        wav.setpos(end_frame - right_length)\n",
    "        right_frames = wav.readframes(right_length)\n",
    "        result = bytearray(b'\\x00'*result_frames*frame_width)\n",
    "        result[:(left_length-crossfade_length)*frame_width] = left_frames[:-crossfade_length*frame_width]\n",
    "        result[-(right_length-crossfade_length)*frame_width:] = right_frames[crossfade_length*frame_width:]\n",
    "        for i in range(crossfade_length):\n",
    "            r = i / (crossfade_length - 1)\n",
    "            l = 1 - r\n",
    "            for channel in range(channels):\n",
    "                signal_left = int.from_bytes(left_frames[(left_length-crossfade_length+i)*frame_width+channel*sample_width:(left_length-crossfade_length+i)*frame_width+(channel+1)*sample_width], 'little', signed=True)\n",
    "                signal_right = int.from_bytes(right_frames[i*frame_width+channel*sample_width:i*frame_width+(channel+1)*sample_width], 'little', signed=True)\n",
    "                result[(left_length-crossfade_length+i)*frame_width+channel*sample_width:(left_length-crossfade_length+i)*frame_width+(channel+1)*sample_width] = int(signal_left*l + signal_right*r).to_bytes(sample_width, 'little', signed=True)\n",
    "        return result\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    frames = []\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        frames.append(Frame(audio[offset:offset + n], timestamp, duration))\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832e1730-5a09-4caf-8a6f-5904aa3370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-path', type=str, default='files/', help='path to video')\n",
    "parser.add_argument('-threshold-duration', type=float, default=0.2, help='threshold duration in seconds')\n",
    "parser.add_argument('-check', type=bool, default=True, help='path to text file')\n",
    "parser.add_argument('-p', type=str, default='results/', help='path to video')\n",
    "parser.add_argument('--threshold-level', type=float, default=-35, help='threshold level in dB')\n",
    "parser.add_argument('--constant', type=float, default=0, help='duration constant transform value')\n",
    "parser.add_argument('--sublinear', type=float, default=0, help='duration sublinear transform factor')\n",
    "parser.add_argument('--linear', type=float, default=0.1, help='duration linear transform factor')\n",
    "parser.add_argument('--save-silence', type=str, help='filename for saving silence')\n",
    "parser.add_argument('--recalculate-time-in-description', type=str, help='path to text file')\n",
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9b7c0ca-cec1-4dd5-b1e6-6e6d1e67fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3655 0.2\n",
      "0.2 0.21731250000000024\n",
      "0.2 0.2\n",
      "0.3039375 0.2085625000000002\n",
      "0.2 0.2110625000000006\n",
      "0.2 0.20468750000000036\n",
      "0.2 0.2296250000000022\n",
      "0.2 0.2\n",
      "0.2 0.22312499999999957\n",
      "0.2 0.23456249999999912\n",
      "0.2 0.2\n",
      "0.43925 0.20949999999999847\n",
      "0.2 0.2\n",
      "0.2 0.2083750000000002\n"
     ]
    }
   ],
   "source": [
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "import collections\n",
    "\n",
    "dir_path = args.path +'*.wav'\n",
    "paths = glob.glob(dir_path)\n",
    "\n",
    "for path in paths:\n",
    "    # print(path)\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    # print('sample rate : {}, samples.shape : {}'.format(sample_rate, samples.shape))\n",
    "\n",
    "    vad = webrtcvad.Vad()\n",
    "    vad.set_mode(3)\n",
    "    # 10, 20, or 30\n",
    "    frame_duration = 10 # ms\n",
    "    frames = frame_generator(frame_duration, samples, sample_rate)\n",
    "    flag = True\n",
    "    for i, frame in enumerate(frames):\n",
    "        if vad.is_speech(frame.bytes, sample_rate):\n",
    "            if flag:\n",
    "                start_idx = i\n",
    "                flag = False\n",
    "            else:\n",
    "                end_idx = i\n",
    "    if start_idx > 1:\n",
    "        start_idx -= 1\n",
    "    if end_idx < len(frames):\n",
    "        end_idx += 1\n",
    "        \n",
    "    audio_start_frame = int(start_idx/100.0*sample_rate*2)\n",
    "    audio_end_frame = int(end_idx/100.0*sample_rate*2)\n",
    "    audio_result_frames = audio_end_frame - audio_start_frame\n",
    "\n",
    "    dst = args.p + path.split(args.path)[-1]\n",
    "    if not os.path.isdir(args.p):\n",
    "        os.mkdir(args.p)\n",
    "    \n",
    "    wav = wave.open(path, mode='rb')\n",
    "    out_wav = wave.open(dst, mode='wb')\n",
    "    channels = wav.getnchannels()\n",
    "    sample_width = wav.getsampwidth()\n",
    "    audio_frame_rate = wav.getframerate()\n",
    "    out_wav.setnchannels(channels)\n",
    "    out_wav.setsampwidth(sample_width)\n",
    "    out_wav.setframerate(audio_frame_rate)\n",
    "    \n",
    "    out_wav.writeframes(compress_audio(wav, audio_start_frame, audio_end_frame, audio_result_frames))\n",
    "    # write(dst, sample_rate, samples_cut)\n",
    "    \n",
    "    out_wav.close()\n",
    "\n",
    "    silences, including_end = find_silences(dst)\n",
    "    if silences[0][0] == 0.0:\n",
    "        start_gap = silences[0][1] - silences[0][0]\n",
    "    else:\n",
    "        start_gap = 0\n",
    "    if including_end:\n",
    "        end_gap = silences[-1][1] - silences[-1][0]\n",
    "    else:\n",
    "        end_gap = 0\n",
    "    \n",
    "    seg = AudioSegment.silent(duration=200)\n",
    "    song = AudioSegment.from_wav(dst)\n",
    "    \n",
    "    if start_gap < 0.2:\n",
    "        start_gap += 0.2\n",
    "        song = seg + song\n",
    "    if end_gap < 0.2:\n",
    "        end_gap += 0.2\n",
    "        song = song + seg\n",
    "    song.export(dst, format=\"wav\")\n",
    "    \n",
    "    # print(start_gap, end_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00f02961-d945-452c-80a1-7b9e0885b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "sample_rate, samples = wavfile.read(path)\n",
    "print(sample_rate)\n",
    "y, sr = librosa.load(path, sr=sample_rate)\n",
    "resample = librosa.resample(y, sr, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e12fcaa-9032-4c53-8263-82c5140f725c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311680,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67600f87-d615-404d-9476-3928c0ebc999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silence",
   "language": "python",
   "name": "silence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
